{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised Binary Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXMypb1kPf3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "573ab031-a6f3-4000-e094-5cd53a162134"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxdW-6AzPoXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = np.genfromtxt('/content/drive/My Drive/Data ML/ec014.42_794_796_798.txt', usecols=list(range(0,256)), skip_header=1)\n",
        "data2 = np.genfromtxt('/content/drive/My Drive/Data ML/ec014.42_795_797_spikes.txt', usecols=list(range(0,256)), skip_header=1)\n",
        "parameters1 = np.genfromtxt('/content/drive/My Drive/Data ML/ec014.42_794_796_798.txt', dtype=None, encoding='UTF-8', usecols=list(range(256,267)), skip_header=1)\n",
        "parameters2 = np.genfromtxt('/content/drive/My Drive/Data ML/ec014.42_795_797_spikes.txt', dtype=None, encoding='UTF-8', usecols=list(range(256,267)), skip_header=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M7LwHjRcSF9",
        "colab_type": "text"
      },
      "source": [
        "2.) Classification of excitatory/inhibitory (over all electrodes in 3 session 794, 796, 798)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWUSASgBcRwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "7916f7c2-5597-453a-ee2e-db7cd4bf76b9"
      },
      "source": [
        "#Classication in 2 groups (excitatory/inhibitory)\n",
        "from keras.constraints import maxnorm\n",
        "\n",
        "#Adjust data\n",
        "data = np.genfromtxt('/content/drive/My Drive/ec014.42_794_796_798.txt', usecols=list(range(0,256)))\n",
        "parameters = np.genfromtxt('/content/drive/My Drive/ec014.42_794_796_798.txt', dtype=None, encoding='UTF-8', usecols=list(range(256,267)))\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "classification = np.empty(shape=(data.shape[0],1))\n",
        "for i in range(0, data.shape[0]):\n",
        "  if parameters[i][8] != '0' and parameters[i][9] == '0': #excit\n",
        "    classification[i] = 0\n",
        "  elif parameters[i][8] == '0' and parameters[i][9] != '0': #inhib\n",
        "    classification[i] = 1\n",
        "  elif parameters[i][8] != '0' and parameters[i][9] != '0': #both-con\n",
        "    classification[i] = 3\n",
        "  else:\n",
        "    classification[i] = 2 #neither\n",
        "  i=i+1\n",
        "data = np.append(data, classification, axis=1)\n",
        "data =data[data[:,256] != 3] #No double con\n",
        "\n",
        "\n",
        "#Divide and reshape data randomly in subset for training and validation\n",
        "training_labels = data[0:(data.shape[0]-10000),256]\n",
        "training_data = data[0:(data.shape[0]-10000),0:256]\n",
        "test_labels = data[(data.shape[0]-10000):(data.shape[0]),256]\n",
        "test_data = data[(data.shape[0]-10000):(data.shape[0]),0:256]\n",
        "training_data = training_data.reshape(training_data.shape[0], training_data.shape[1],1)\n",
        "test_data = test_data.reshape(test_data.shape[0], test_data.shape[1],1)\n",
        "\n",
        "print(\"Excitatory:\", len(classification[classification[:,0] == 0]))\n",
        "print(\"Inhibitory:\", len(classification[classification[:,0] == 1]))\n",
        "print(\"Neither:\", len(classification[classification[:,0] == 2]))\n",
        "print(\"total:\", data.shape[0])\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Conv1D(filters=256, kernel_size=16, activation='relu', input_shape=(256,1)),\n",
        "                                    tf.keras.layers.Conv1D(filters=256, kernel_size=16, activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling1D(pool_size=3),\n",
        "                                    tf.keras.layers.Conv1D(filters=128, kernel_size=8, activation='relu'),\n",
        "                                    tf.keras.layers.Conv1D(filters=128, kernel_size=8, activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling1D(pool_size=3),\n",
        "                                    tf.keras.layers.Conv1D(filters=100, kernel_size=4, activation='relu'),\n",
        "                                    tf.keras.layers.Conv1D(filters=100, kernel_size=4, activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling1D(pool_size=3),\n",
        "                                    tf.keras.layers.Conv1D(filters=100, kernel_size=2, activation='relu'),\n",
        "                                    tf.keras.layers.Conv1D(filters=100, kernel_size=2, activation='relu'),\n",
        "                                    tf.keras.layers.GlobalAveragePooling1D(), \n",
        "                                    tf.keras.layers.Dropout(0.3),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu', kernel_constraint=maxnorm(3)),\n",
        "                                    tf.keras.layers.Dense(3, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_data, training_labels, epochs=5)\n",
        "\n",
        "print(\"The model classifies accurately in\", model.evaluate(test_data, test_labels)[1]*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(81931, 256)\n",
            "Excitatory: 13155\n",
            "Inhibitory: 38497\n",
            "Neither: 30278\n",
            "total: 81930\n",
            "Epoch 1/5\n",
            "2248/2248 [==============================] - 2450s 1s/step - loss: 0.1831 - accuracy: 0.9331\n",
            "Epoch 2/5\n",
            "2248/2248 [==============================] - 2453s 1s/step - loss: 0.1024 - accuracy: 0.9652\n",
            "Epoch 3/5\n",
            "2248/2248 [==============================] - 2438s 1s/step - loss: 0.0882 - accuracy: 0.9713\n",
            "Epoch 4/5\n",
            "2248/2248 [==============================] - 2429s 1s/step - loss: 0.0791 - accuracy: 0.9735\n",
            "Epoch 5/5\n",
            "2248/2248 [==============================] - 2427s 1s/step - loss: 0.0725 - accuracy: 0.9764\n",
            "313/313 [==============================] - 85s 272ms/step - loss: 0.1079 - accuracy: 0.9708\n",
            "The model classifies accurately in 97.079998254776 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}