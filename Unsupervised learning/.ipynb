{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from time import time\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting correct path \n",
    "cwd = os.getcwd() # Get current working directory\n",
    "root_folder = os.sep + \"ML-Neuron-Classification\"\n",
    "sys.path.insert(0, cwd[:(cwd.index(root_folder)+len(root_folder))] + os.sep)\n",
    "from utils.helper_functions import*\n",
    "from utils.unpacking_dat_files import*\n",
    "\n",
    "nmi = normalized_mutual_info_score\n",
    "ari = adjusted_rand_score\n",
    "date = datetime.date.today()\n",
    "\n",
    "#Upload data\n",
    "data_path = 'C:/Users/Marius/Documents/Datasets/.txt/ec014.42_794_796_798_spikes.txt'\n",
    "x = np.genfromtxt(data_path, usecols=list(range(0,256)), skip_header=1)\n",
    "parameters = np.genfromtxt(data_path, dtype=None, encoding='UTF-8', usecols=list(range(256,267)), skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Excting traces: 13155\n",
      "#Inhibiting traces: 13155\n",
      "#Total traces: 26310\n",
      "Self-training with 26310 traces!\n",
      "[0. 1.]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#Include paramter information into main array\n",
    "classification = np.empty(shape=(x.shape[0],1))\n",
    "for i in range(0, x.shape[0]):\n",
    "  if parameters[i][8] != 0 and parameters[i][9] == 0: #excitatory\n",
    "    classification[i] = 0\n",
    "  elif parameters[i][8] == 0 and parameters[i][9] != 0: #inhibitory\n",
    "    classification[i] = 1\n",
    "  else:\n",
    "    classification[i] = 2 #neither\n",
    "  i=i+1\n",
    "x = np.append(x, classification, axis=1)\n",
    "x = x[x[:,256] != 2] #No neither\n",
    "\n",
    "excits = x[x[:,256] == 0]\n",
    "inhibs = x[x[:,256] == 1]\n",
    "print(\"#Excting traces:\", excits.shape[0])\n",
    "\n",
    "\n",
    "rnd = np.random.choice(inhibs.shape[0], excits.shape[0], replace=False) #As more inhibs, choose randomly from inhibibitory to get same number of both types\n",
    "inhibs = inhibs[rnd,:]\n",
    "print(\"#Inhibiting traces:\", inhibs.shape[0])\n",
    "x = np.concatenate([excits, inhibs], axis=0) #back together\n",
    "x = np.take(x,np.random.permutation(x.shape[0]),axis=0,out=x) #random shuffle\n",
    "print(\"#Total traces:\", x.shape[0])\n",
    "\n",
    "Y_train = x[:,256]\n",
    "X = x[:,:-1]\n",
    "\n",
    "X_train = normalization_train(X)\n",
    "\n",
    "print('Self-training with', X_train.shape[0], 'traces!')\n",
    "n_clusters = len(np.unique(Y_train))\n",
    "print(np.unique(Y_train))\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8979475484606614\n",
      "0.9072215887495249\n",
      "0.9127708095781072\n",
      "0.9047890535917902\n",
      "0.8976434815659445\n",
      "0.8669327251995439\n",
      "0.9155454199923984\n",
      "0.8988217407829723\n",
      "0.9253515773470163\n",
      "0.9130368681109844\n",
      "0.9144051691372101\n",
      "0.9242873432155074\n",
      "0.911250475104523\n",
      "0.9055492208285822\n",
      "0.8952489547700494\n",
      "0.865488407449639\n",
      "0.9093120486507031\n",
      "0.9052451539338654\n",
      "0.8836944127708096\n",
      "0.9136830102622577\n",
      "[0.89794755 0.90722159 0.91277081 0.90478905 0.89764348 0.86693273\n",
      " 0.91554542 0.89882174 0.92535158 0.91303687 0.91440517 0.92428734\n",
      " 0.91125048 0.90554922 0.89524895 0.86548841 0.90931205 0.90524515\n",
      " 0.88369441 0.91368301]\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "dims = [X_train.shape[-1], 500, 500, 2000, 7]\n",
    "k_means = []\n",
    "#init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "pretrain_optimizer = 'Adam'\n",
    "pretrain_epochs = 50\n",
    "batch_size = 64\n",
    "save_dir = 'C:/Users/Marius/Documents/GitHub/ML-Neuron-Classification/Unsupervised learning/Model weights'\n",
    "\n",
    "for i in range (20):\n",
    "    def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "\t    n_stacks = len(dims) - 1\n",
    "\t    # input\n",
    "\t    input_img = Input(shape=(dims[0],), name='input')\n",
    "\t    x = input_img\n",
    "\t    # internal layers in encoder\n",
    "\t    for i in range(n_stacks-1):\n",
    "\t        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n",
    "\n",
    "\t    # hidden layer\n",
    "\t    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n",
    "\n",
    "\t    x = encoded\n",
    "\t    # internal layers in decoder\n",
    "\t    for i in range(n_stacks-1, 0, -1):\n",
    "\t        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n",
    "\n",
    "\t    # output\n",
    "\t    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n",
    "\t    decoded = x\n",
    "\t    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')\n",
    "    autoencoder, encoder = autoencoder(dims)\n",
    "    autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "    name_save_process = f'/2020-10-19_DEC_{pretrain_epochs}epochs_{i}_pretrain.h5'\n",
    "    name_save_final = f'/2020-10-19_DEC_{pretrain_epochs}epochs_{i}_final.h5'\n",
    "    autoencoder.load_weights(save_dir + name_save_process)\n",
    "    #Clustering\n",
    "    clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "    model = Model(inputs=encoder.input, outputs=clustering_layer)\n",
    "    model.compile(optimizer='Adam', loss='kld')\n",
    "\n",
    "    #Initialize Clusters using K-means\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50)\n",
    "    y_pred = kmeans.fit_predict(encoder.predict(X_train))\n",
    "    y_pred_last = np.copy(y_pred)\n",
    "    model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "    print(acc(Y_train, y_pred))\n",
    "    k_means = np.append(k_means, acc(Y_train, y_pred))\n",
    "\n",
    "print(k_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(k_means)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "dims = [X_train.shape[-1], 500, 500, 2000, 7]\n",
    "#init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "pretrain_optimizer = 'Adam'\n",
    "pretrain_epochs = 50\n",
    "batch_size = 64\n",
    "save_dir = 'C:/Users/Marius/Documents/GitHub/ML-Neuron-Classification/Unsupervised learning/Model weights'\n",
    "name_save_process = f'/{date}_DEC_{pretrain_epochs}epochs_pretrain_1.h5'\n",
    "name_save_final = f'/{date}_DEC_{pretrain_epochs}epochs_final_1.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26310 samples\n",
      "Epoch 1/50\n",
      "26310/26310 [==============================] - 15s 568us/sample - loss: 1.7863e-04\n",
      "Epoch 2/50\n",
      "26310/26310 [==============================] - 15s 555us/sample - loss: 1.2501e-04\n",
      "Epoch 3/50\n",
      "26310/26310 [==============================] - 15s 567us/sample - loss: 1.1417e-04\n",
      "Epoch 4/50\n",
      "26310/26310 [==============================] - 15s 574us/sample - loss: 1.1225e-04\n",
      "Epoch 5/50\n",
      "26310/26310 [==============================] - 15s 571us/sample - loss: 1.1131e-04\n",
      "Epoch 6/50\n",
      "26310/26310 [==============================] - 17s 640us/sample - loss: 1.1050e-04\n",
      "Epoch 7/50\n",
      "26310/26310 [==============================] - 15s 579us/sample - loss: 1.0980e-04\n",
      "Epoch 8/50\n",
      "26310/26310 [==============================] - 15s 570us/sample - loss: 1.0924e-04\n",
      "Epoch 9/50\n",
      "26310/26310 [==============================] - 15s 578us/sample - loss: 1.0869e-04\n",
      "Epoch 10/50\n",
      "26310/26310 [==============================] - 16s 596us/sample - loss: 1.0829e-04\n",
      "Epoch 11/50\n",
      "26310/26310 [==============================] - 16s 624us/sample - loss: 1.0798e-04\n",
      "Epoch 12/50\n",
      "26310/26310 [==============================] - 15s 568us/sample - loss: 1.0777e-04\n",
      "Epoch 13/50\n",
      "26310/26310 [==============================] - 15s 570us/sample - loss: 1.0712e-04\n",
      "Epoch 14/50\n",
      "26310/26310 [==============================] - 16s 589us/sample - loss: 1.0691e-04\n",
      "Epoch 15/50\n",
      "26310/26310 [==============================] - 16s 605us/sample - loss: 1.0647e-04\n",
      "Epoch 16/50\n",
      "26310/26310 [==============================] - 16s 590us/sample - loss: 1.0608e-04\n",
      "Epoch 17/50\n",
      "26310/26310 [==============================] - 15s 589us/sample - loss: 1.0593e-04\n",
      "Epoch 18/50\n",
      "26310/26310 [==============================] - 17s 657us/sample - loss: 1.0571e-04\n",
      "Epoch 19/50\n",
      "26310/26310 [==============================] - 16s 590us/sample - loss: 1.0537e-04\n",
      "Epoch 20/50\n",
      "26310/26310 [==============================] - 16s 594us/sample - loss: 1.0539e-04\n",
      "Epoch 21/50\n",
      "26310/26310 [==============================] - 16s 599us/sample - loss: 1.0487e-04\n",
      "Epoch 22/50\n",
      "26310/26310 [==============================] - 16s 597us/sample - loss: 1.0462e-04\n",
      "Epoch 23/50\n",
      "26310/26310 [==============================] - 17s 647us/sample - loss: 1.0433e-04\n",
      "Epoch 24/50\n",
      "26310/26310 [==============================] - 16s 610us/sample - loss: 1.0411e-04\n",
      "Epoch 25/50\n",
      "26310/26310 [==============================] - 16s 597us/sample - loss: 1.0389e-04\n",
      "Epoch 26/50\n",
      "26310/26310 [==============================] - 17s 628us/sample - loss: 1.0368e-04\n",
      "Epoch 27/50\n",
      "26310/26310 [==============================] - 16s 615us/sample - loss: 1.0339e-04\n",
      "Epoch 28/50\n",
      "26310/26310 [==============================] - 16s 605us/sample - loss: 1.0322e-04\n",
      "Epoch 29/50\n",
      "26310/26310 [==============================] - 16s 599us/sample - loss: 1.0290e-04\n",
      "Epoch 30/50\n",
      "26310/26310 [==============================] - 16s 600us/sample - loss: 1.0268e-04\n",
      "Epoch 31/50\n",
      "26310/26310 [==============================] - 16s 603us/sample - loss: 1.0241e-04\n",
      "Epoch 32/50\n",
      "26310/26310 [==============================] - 16s 612us/sample - loss: 1.0235e-04\n",
      "Epoch 33/50\n",
      "26310/26310 [==============================] - 16s 620us/sample - loss: 1.0193e-04\n",
      "Epoch 34/50\n",
      "26310/26310 [==============================] - 16s 592us/sample - loss: 1.0185e-04\n",
      "Epoch 35/50\n",
      "26310/26310 [==============================] - 16s 608us/sample - loss: 1.0150e-04\n",
      "Epoch 36/50\n",
      "26310/26310 [==============================] - 17s 628us/sample - loss: 1.0130e-04\n",
      "Epoch 37/50\n",
      "26310/26310 [==============================] - 16s 620us/sample - loss: 1.0116e-04\n",
      "Epoch 38/50\n",
      "26310/26310 [==============================] - 16s 611us/sample - loss: 1.0092e-04\n",
      "Epoch 39/50\n",
      "26310/26310 [==============================] - 17s 634us/sample - loss: 1.0069e-04\n",
      "Epoch 40/50\n",
      "26310/26310 [==============================] - 16s 614us/sample - loss: 1.0055e-04\n",
      "Epoch 41/50\n",
      "26310/26310 [==============================] - 16s 617us/sample - loss: 1.0046e-04\n",
      "Epoch 42/50\n",
      "26310/26310 [==============================] - 16s 597us/sample - loss: 9.9944e-05\n",
      "Epoch 43/50\n",
      "26310/26310 [==============================] - 16s 600us/sample - loss: 9.9749e-05\n",
      "Epoch 44/50\n",
      "26310/26310 [==============================] - 17s 630us/sample - loss: 9.9521e-05\n",
      "Epoch 45/50\n",
      "26310/26310 [==============================] - 16s 605us/sample - loss: 9.9316e-05\n",
      "Epoch 46/50\n",
      "26310/26310 [==============================] - 16s 623us/sample - loss: 9.9220e-05\n",
      "Epoch 47/50\n",
      "26310/26310 [==============================] - 17s 638us/sample - loss: 9.9114e-05\n",
      "Epoch 48/50\n",
      "26310/26310 [==============================] - 17s 648us/sample - loss: 9.8740e-05\n",
      "Epoch 49/50\n",
      "26310/26310 [==============================] - 17s 630us/sample - loss: 9.8550e-05\n",
      "Epoch 50/50\n",
      "26310/26310 [==============================] - 17s 634us/sample - loss: 9.8307e-05\n"
     ]
    }
   ],
   "source": [
    "autoencoder, encoder = autoencoder(dims, init=init)\n",
    "autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=pretrain_epochs)\n",
    "autoencoder.save_weights(save_dir + name_save_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optinal: Load weights\n",
    "autoencoder.load_weights(save_dir + name_save_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Initialize Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9054732041049031\n"
     ]
    }
   ],
   "source": [
    "#Clustering\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input, outputs=clustering_layer)\n",
    "model.compile(optimizer='Adam', loss='kld')\n",
    "\n",
    "#Initialize Clusters using K-means\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=50)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(X_train))\n",
    "y_pred_last = np.copy(y_pred)\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "print(acc(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters iterative process\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 8000\n",
    "update_interval = 140\n",
    "index_array = np.arange(X_train.shape[0])\n",
    "tol = 0.0001 # tolerance threshold to stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.90547, nmi = 0.61674, ari = 0.65762  ; loss= 0\n",
      "Iter 140: acc = 0.91323, nmi = 0.63425, ari = 0.68301  ; loss= 0.0\n",
      "Iter 280: acc = 0.91619, nmi = 0.63901, ari = 0.69285  ; loss= 2e-05\n",
      "Iter 420: acc = 0.91722, nmi = 0.64401, ari = 0.69627  ; loss= 0.00011\n",
      "Iter 560: acc = 0.91680, nmi = 0.64066, ari = 0.69488  ; loss= 0.00083\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-9bd8be697963>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mite\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mite\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mupdate_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# update the auxiliary target distribution p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(X_train, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if Y_train is not None:\n",
    "            acc_var = np.round(acc(Y_train, y_pred), 5)\n",
    "            nmi_var = np.round(nmi(Y_train, y_pred), 5)\n",
    "            ari_var = np.round(ari(Y_train, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc_var, nmi_var, ari_var), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion - model convergence\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, X_train.shape[0])]\n",
    "    loss = model.train_on_batch(x=X_train[idx], y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= X_train.shape[0] else 0\n",
    "\n",
    "model.save_weights(save_dir + name_save_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
