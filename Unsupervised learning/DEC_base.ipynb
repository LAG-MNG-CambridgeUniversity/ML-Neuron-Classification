{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "\n",
    "from time import time\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting correct path \n",
    "cwd = os.getcwd() # Get current working directory\n",
    "root_folder = os.sep + \"ML-Neuron-Classification\"\n",
    "sys.path.insert(0, cwd[:(cwd.index(root_folder)+len(root_folder))] + os.sep)\n",
    "from utils.helper_functions import*\n",
    "from utils.unpacking_dat_files import*\n",
    "from utils.autoencoder import*\n",
    "\n",
    "nmi = normalized_mutual_info_score\n",
    "ari = adjusted_rand_score\n",
    "date = datetime.date.today()\n",
    "\n",
    "#Upload data\n",
    "data_path = 'C:/Users/Marius/Documents/Datasets/.txt/ec014.42_794_796_798_spikes.txt'\n",
    "x = np.genfromtxt(data_path, usecols=list(range(0,256)), skip_header=1)\n",
    "parameters = np.genfromtxt(data_path, dtype=None, encoding='UTF-8', usecols=list(range(256,267)), skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Exciting traces: 13155\n",
      "#Inhibiting traces: 13155\n",
      "#Total traces: 26310\n",
      "Self-training with 26310 traces!\n",
      "[0. 1.]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#Include paramter information into main array\n",
    "classification = np.empty(shape=(x.shape[0],1))\n",
    "for i in range(0, x.shape[0]):\n",
    "  if parameters[i][8] != 0 and parameters[i][9] == 0: #excitatory\n",
    "    classification[i] = 0\n",
    "  elif parameters[i][8] == 0 and parameters[i][9] != 0: #inhibitory\n",
    "    classification[i] = 1\n",
    "  else:\n",
    "    classification[i] = 2 #neither\n",
    "  i=i+1\n",
    "x = np.append(x, classification, axis=1)\n",
    "x = x[x[:,256] != 2] #No neither\n",
    "\n",
    "excits = x[x[:,256] == 0]\n",
    "inhibs = x[x[:,256] == 1]\n",
    "\n",
    "#rnd1 = np.random.choice(excits.shape[0], 10000, replace=False) #As more inhibs, choose randomly from inhibibitory to get same number of both types\n",
    "rnd2 = np.random.choice(inhibs.shape[0], excits.shape[0], replace=False) #As more inhibs, choose randomly from inhibibitory to get same number of both types\n",
    "#excits = excits[rnd1,:]\n",
    "inhibs = inhibs[rnd2,:]\n",
    "print(\"#Exciting traces:\", excits.shape[0])\n",
    "print(\"#Inhibiting traces:\", inhibs.shape[0])\n",
    "x = np.concatenate([excits, inhibs], axis=0) #back together\n",
    "x = np.take(x,np.random.permutation(x.shape[0]),axis=0,out=x) #random shuffle\n",
    "print(\"#Total traces:\", x.shape[0])\n",
    "\n",
    "Y_train = x[:,256]\n",
    "X = x[:,:-1]\n",
    "\n",
    "#X = isolate_maximum_electrode(X)\n",
    "X_train = normalization_train(X)\n",
    "\n",
    "#Reshape data\n",
    "#X_train = X_train.reshape(X_train.shape[0], 8, 32)\n",
    "#X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "\n",
    "print('Self-training with', X_train.shape[0], 'traces!')\n",
    "n_clusters = len(np.unique(Y_train))\n",
    "print(np.unique(Y_train))\n",
    "print(n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "dims = [X_train.shape[-1], 500, 500, 2000, 7]\n",
    "#init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "pretrain_optimizer = 'Adam'#tf.keras.optimizers.Adam(learning_rate=0.001, decay=1.e-6)\n",
    "pretrain_epochs = 30\n",
    "batch_size = 128\n",
    "save_dir = 'C:/Users/Marius/Documents/Model weights/Testing_variationalAutoencoder'\n",
    "name_save_process = f'{date}_1_DEC_{pretrain_epochs}epochs_pretrain.h5'\n",
    "name_save_final = f'{date}_1_DEC_{pretrain_epochs}epochs_final.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26310 samples\n",
      "Epoch 1/30\n",
      "26310/26310 [==============================] - 11s 408us/sample - loss: 1.7272e-04\n",
      "Epoch 2/30\n",
      "26310/26310 [==============================] - 11s 431us/sample - loss: 1.2385e-04\n",
      "Epoch 3/30\n",
      "26310/26310 [==============================] - 13s 476us/sample - loss: 1.1972e-04\n",
      "Epoch 4/30\n",
      "26310/26310 [==============================] - 12s 444us/sample - loss: 1.1694e-04\n",
      "Epoch 5/30\n",
      "26310/26310 [==============================] - 11s 405us/sample - loss: 1.1474e-04\n",
      "Epoch 6/30\n",
      "26310/26310 [==============================] - 10s 375us/sample - loss: 1.1342e-04 -\n",
      "Epoch 7/30\n",
      "26310/26310 [==============================] - 10s 371us/sample - loss: 1.1254e-04\n",
      "Epoch 8/30\n",
      "26310/26310 [==============================] - 10s 375us/sample - loss: 1.1175e-04\n",
      "Epoch 9/30\n",
      "26310/26310 [==============================] - 10s 374us/sample - loss: 1.1130e-04\n",
      "Epoch 10/30\n",
      "26310/26310 [==============================] - 10s 377us/sample - loss: 1.1090e-04\n",
      "Epoch 11/30\n",
      "26310/26310 [==============================] - 10s 396us/sample - loss: 1.1024e-04\n",
      "Epoch 12/30\n",
      "26310/26310 [==============================] - 11s 401us/sample - loss: 1.0985e-04\n",
      "Epoch 13/30\n",
      "26310/26310 [==============================] - 10s 379us/sample - loss: 1.0933e-04\n",
      "Epoch 14/30\n",
      "26310/26310 [==============================] - 10s 371us/sample - loss: 1.0914e-04\n",
      "Epoch 15/30\n",
      "26310/26310 [==============================] - 10s 373us/sample - loss: 1.0883e-04\n",
      "Epoch 16/30\n",
      "26310/26310 [==============================] - 11s 403us/sample - loss: 1.0855e-04\n",
      "Epoch 17/30\n",
      "26310/26310 [==============================] - 11s 403us/sample - loss: 1.0822e-04\n",
      "Epoch 18/30\n",
      "26310/26310 [==============================] - 10s 395us/sample - loss: 1.0796e-04\n",
      "Epoch 19/30\n",
      "26310/26310 [==============================] - 11s 426us/sample - loss: 1.0785e-04\n",
      "Epoch 20/30\n",
      "26310/26310 [==============================] - 11s 404us/sample - loss: 1.0754e-04\n",
      "Epoch 21/30\n",
      "26310/26310 [==============================] - 10s 387us/sample - loss: 1.0730e-04\n",
      "Epoch 22/30\n",
      "26310/26310 [==============================] - 11s 401us/sample - loss: 1.0707e-04\n",
      "Epoch 23/30\n",
      "26310/26310 [==============================] - 10s 390us/sample - loss: 1.0692e-04\n",
      "Epoch 24/30\n",
      "26310/26310 [==============================] - 10s 386us/sample - loss: 1.0681e-04\n",
      "Epoch 25/30\n",
      "26310/26310 [==============================] - 10s 384us/sample - loss: 1.0659e-04\n",
      "Epoch 26/30\n",
      "26310/26310 [==============================] - 10s 382us/sample - loss: 1.0637e-04\n",
      "Epoch 27/30\n",
      "26310/26310 [==============================] - 10s 382us/sample - loss: 1.0612e-04\n",
      "Epoch 28/30\n",
      "26310/26310 [==============================] - 10s 383us/sample - loss: 1.0599e-04\n",
      "Epoch 29/30\n",
      "26310/26310 [==============================] - 11s 408us/sample - loss: 1.0574e-04\n",
      "Epoch 30/30\n",
      "26310/26310 [==============================] - 10s 398us/sample - loss: 1.0569e-04\n"
     ]
    }
   ],
   "source": [
    "autoencoder, encoder = autoencoder(dims)\n",
    "#autoencoder, encoder = autoencoder_LSTM(dims, X_train)\n",
    "#autoencoder, encoder = autoencoder_LSTM_Marius(X_train, dims)\n",
    "#autoencoder, encoder = autoencoder_LSTM_2D(dims, X_train)\n",
    "autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "history = autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=pretrain_epochs)\n",
    "#autoencoder.save_weights(save_dir + name_save_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optinal: Load weights\n",
    "autoencoder, encoder = autoencoder_LSTM(dims, X_train)\n",
    "autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "autoencoder.load_weights(save_dir + name_save_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24754742  0.07913704  0.14875537 -0.14176694  0.11515892  0.03148605\n",
      "   0.06488651]]\n"
     ]
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n",
    "print(encoder.predict(X_train[0:1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Initialize Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6636640060813379\n"
     ]
    }
   ],
   "source": [
    "#Gaussian miture\n",
    "from sklearn.mixture import GaussianMixture\n",
    "encoded = encoder.predict(X_train)\n",
    "model = GaussianMixture(n_components=2, init_params='random')\n",
    "y_pred = model.fit_predict(encoded)\n",
    "print(acc(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.13599819, -0.00358406,  0.00446006,  0.00564998, -0.04596641,\n",
      "        -0.07003628, -0.04023524],\n",
      "       [ 0.06863925, -0.03387946, -0.01267099, -0.02621547,  0.03027254,\n",
      "         0.11539891,  0.00264926]], dtype=float32)]\n",
      "0.899809958190802\n"
     ]
    }
   ],
   "source": [
    "#Clustering\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input, outputs=clustering_layer)\n",
    "model.compile(optimizer='Adam', loss='kld')\n",
    "\n",
    "#Initialize Clusters using K-means\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=50)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(X_train))\n",
    "y_pred_last = np.copy(y_pred)\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "print(acc(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819080197643482\n",
      "[[ 0.05672107 -0.00879298 -0.00681134 -0.03053775  0.02108587  0.05046024\n",
      "   0.00143355]\n",
      " [-0.16348985 -0.02285735  0.00189514  0.01611465 -0.05145793 -0.04076022\n",
      "  -0.04727955]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "encoded = encoder.predict(X_train)\n",
    "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "y_pred = cluster.fit_predict(encoded)\n",
    "X_pred = encoder.predict(X_train)\n",
    "X_0 = X_pred[y_pred[:]==0]\n",
    "X_1 = X_pred[y_pred[:]==1]\n",
    "cluster_centroids = np.array([np.mean(X_0, axis=0),np.mean(X_1, axis=0)])\n",
    "print(acc(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(name='clustering').set_weights([cluster_centroids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters iterative process\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 2000\n",
    "update_interval = 140\n",
    "index_array = np.arange(X_train.shape[0])\n",
    "tol = 0.0001 # tolerance threshold to stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.92965, nmi = 0.66139, ari = 0.73837  ; loss= 0\n",
      "Iter 140: acc = 0.92904, nmi = 0.66023, ari = 0.73629  ; loss= 0.0\n",
      "Iter 280: acc = 0.93238, nmi = 0.66982, ari = 0.74781  ; loss= 2e-05\n",
      "Iter 420: acc = 0.93561, nmi = 0.67936, ari = 0.75903  ; loss= 8e-05\n",
      "Iter 560: acc = 0.93630, nmi = 0.68146, ari = 0.76141  ; loss= 0.00103\n",
      "Iter 700: acc = 0.93710, nmi = 0.68359, ari = 0.76420  ; loss= 0.0043\n",
      "Iter 840: acc = 0.93588, nmi = 0.67862, ari = 0.75996  ; loss= 0.01572\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9bd8be697963>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1076\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m           standalone=True)\n\u001b[0m\u001b[0;32m   1079\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m   1080\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[0;32m    431\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(X_train, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if Y_train is not None:\n",
    "            acc_var = np.round(acc(Y_train, y_pred), 5)\n",
    "            nmi_var = np.round(nmi(Y_train, y_pred), 5)\n",
    "            ari_var = np.round(ari(Y_train, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc_var, nmi_var, ari_var), ' ; loss=', loss)\n",
    "\n",
    "        # check stop criterion - model convergence\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, X_train.shape[0])]\n",
    "    loss = model.train_on_batch(x=X_train[idx], y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= X_train.shape[0] else 0\n",
    "\n",
    "model.save_weights(save_dir + name_save_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
